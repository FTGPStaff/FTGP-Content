{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc9841e8",
   "metadata": {},
   "source": [
    "# Lab Exercise: Hybrid Smart Contracts & Decentralised AI Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf242742",
   "metadata": {},
   "source": [
    "## Machine Learning Model - A Simple Price Prediction Model Generation\n",
    "\n",
    "### 1.1 Introduction\n",
    "In this sample project, you will explore the lifecycle of a **Hybrid Smart Contract**. You may execute the provided Python scripts on your local device to generate a Machine Learning (ML) model from scratch, or utilise the pre-trained model stored in the `model/` directory. This model is already stored on **Pinata IPFS**, and its Content Identifier (CID) is hardcoded into the smart contract for simplicity. \n",
    "\n",
    "This project demonstrates the separation of concerns in decentralised systems: performing heavy statistical computation off-chain while maintaining immutable execution on-chain.\n",
    "\n",
    "The figure below illustrates the process flow of the application.\n",
    "\n",
    "![Process Flow](image/process_flow.png)\n",
    "\n",
    "---\n",
    "\n",
    "### 1.2 Training Methodology and Exploratory Data Analysis (EDA)\n",
    "We begin by developing the ML model locally because on-chain training is computationally prohibitive due to EVM gas costs. \n",
    "\n",
    "**The Workflow:**\n",
    "* **Data Acquisition**: We download historical time-series data for the identified cryptocurrency tokens and store it in a local environment.\n",
    "* **Correlation Analysis**: We perform initial statistical analysis to determine the strength of the linear relationship between the chosen assets.\n",
    "* **Visualisation**: We will project the data graphs to analyse any correlations.\n",
    "* **Seasonal Analysis**: While a seasonal analysis could be conducted to identify periodic fluctuations, it is omitted here to maintain a focus on the core regression logic.\n",
    "\n",
    "#### Definition: Log-Differences\n",
    "We train the model based on **log-differences** (log-returns) rather than raw price data.\n",
    "> **Why use log-differences?**\n",
    "> Raw price data is typically non-stationary, meaning its statistical properties (mean, variance) change over time, which can lead to spurious regression results. Log-differences help achieve **stationarity** and represent the relative percentage change, which is more effective for scaling into the fixed-point integer math used in Solidity.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.3 Model Persistence and Decentralised Storage\n",
    "Once the model is trained, the resulting parameters (Slope $\\alpha$ and Intercept $\\beta$) are stored as a `.json` file. \n",
    "\n",
    "* **IPFS Deployment**: We store this file on **Pinata**, a pinning service for the **InterPlanetary File System (IPFS)**.\n",
    "* **Content Addressing**: Unlike traditional URLs, IPFS uses **Content Identifiers (CIDs)**. This ensures that the model parameters are immutable; if the data in the file changes, the CID changes, providing a cryptographic guarantee of data integrity for our smart contract.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.4 On-Chain Inference via Chainlink DON\n",
    "The final stage of the project utilises the **Remix IDE** and the **Sepolia Testnet**. Here, we will fetch the stored model parameters and start price predictions.\n",
    "\n",
    "**The Technical Challenge:**\n",
    "The Ethereum Virtual Machine (EVM) cannot natively perform HTTP requests to fetch files from the web, and parsing complex strings (like JSON) on-chain is extremely expensive.\n",
    "\n",
    "**The Solution:**\n",
    "We deploy a smart contract that leverages a **Chainlink Decentralised Oracle Network (DON)**.\n",
    "1. **Fetch & Parse**: The DON fetches the `model.json` file from Pinata IPFS and parses it off-chain.\n",
    "2. **Data Delivery**: The DON returns only the essential integer values to our Solidity contract.\n",
    "3. **On-Chain Inference**: The contract executes the `predictEth` function using the latest model parameters to forecast Ethereum prices based on:\n",
    "    * **Past Bitcoin Price**\n",
    "    * **Current Bitcoin Price**\n",
    "    * **Past Ethereum Price**\n",
    "\n",
    "---\n",
    "\n",
    "### 1.5 Learning Objectives\n",
    "This project aims to demonstrate:\n",
    "* **Off-Chain Intelligence**: How an AI model can be trained locally to save on-chain resources.\n",
    "* **Decentralised Persistence**: How to secure model files on a decentralised storage layer like **IPFS**.\n",
    "* **Oracle Middleware**: How to bridge IPFS-stored data into Solidity using **Chainlink Functions**.\n",
    "* **Gas Optimisation**: By offloading expensive operations off-chain—such as **ML model training** and **complex string/JSON parsing**, you will learn to determine which processes should be moved outside of the EVM to maintain economic viability and avoid block gas limits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0f07b4",
   "metadata": {},
   "source": [
    "## Python Library Imports\n",
    "\n",
    "| Library | Key Functionality | Project Utility |\n",
    "|---|---|---|\n",
    "| **yfinance** | Accesses financial data from the Yahoo Finance API. | Used to fetch historical price data. |\n",
    "| **Pandas** | Provides advanced data structures like **DataFrames** for data manipulation. | Used for cleaning data, synchronising timestamps, and calculating **log-differences**. |\n",
    "| **NumPy** | Fundamental package for scientific computing and multi-dimensional array operations. | Handles the underlying mathematical computations and vectorised operations. |\n",
    "| **Matplotlib** | A plotting library for creating static, animated, and interactive visualisations. | Used to project data onto graphs to analyse asset correlations visually. |\n",
    "| **scikit-learn** | A comprehensive machine learning library for predictive data analysis. | Implements the **Linear Regression** algorithm. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a706db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this only if the code below causes an error\n",
    "!pip install numpy pandas matplotlib yfinance scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7098d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# Data Manipulation and Numerical Analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Financial Data Acquisition and Web Requests\n",
    "import yfinance as yf\n",
    "import requests  \n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "# Ensures plots are rendered inline if using Jupyter/Google Colab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7debfd71",
   "metadata": {},
   "source": [
    "### Data Acquisition and Environment Setup\n",
    "\n",
    "Before training the model, we must retrieve historical market data and organise it into a format suitable for statistical analysis. The following code block handles the environment configuration and data ingestion.\n",
    "\n",
    "#### 1. Configuration and Path Management\n",
    "We utilise the `pathlib` library to define **Environment Paths**. Unlike standard strings, `Path` objects ensure the script remains cross-platform, functioning correctly on any operating system.\n",
    "* **Asset Selection**: We define a list `cryptos = [\"ETH\", \"BTC\"]` to target our specific assets.\n",
    "* **Currency Denomination**: The `VS` variable (e.g., \"USD\") ensures all prices are denominated in the same fiat currency for valid comparison.\n",
    "\n",
    "#### 2. Automated Data Ingestion via yfinance\n",
    "The script uses the `yf.download()` function to fetch data directly from the Yahoo Finance API.\n",
    "* **Tickers**: We dynamically build ticker symbols (e.g., `ETH-USD`) to match the API's requirements.\n",
    "* **Parameters**: We define a historical window from 2018 to 2026 with a `1d` (daily) interval to capture sufficient volatility for regression.\n",
    "\n",
    "#### 3. Data Transformation and Cleaning\n",
    "Raw data from APIs is often \"noisy\" or structured for multiple assets simultaneously. We perform two critical transformation steps:\n",
    "* **DataFrame Construction**: We extract only the `Close` prices for our chosen assets and consolidate them into a single **Pandas DataFrame**.\n",
    "* **Ensuring Data Veracity**: We use `dropna(how=\"any\")` to remove rows where data might be missing for one of the assets. This ensures the model is trained only on overlapping dates where both BTC and ETH prices are verified.\n",
    "\n",
    "#### 4. Local Persistence\n",
    "Finally, the script creates the necessary directory structure and saves the cleaned dataset as a `.csv` file. This provides a local \"checkpoint,\" allowing you to resume analysis without re-downloading data from the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc01a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENVIRONMENT PATHS: Utilises pathlib for cross-platform compatibility\n",
    "DATA_PATH = Path(\"./data/crypto_price.csv\")\n",
    "MODEL_PATH = Path(\"./model/model.json\")\n",
    "\n",
    "# DATA CONFIGURATION\n",
    "# Feel free to modify the cryptos list to experiment with different asset correlations\n",
    "cryptos = [\"ETH\", \"BTC\"]\n",
    "\n",
    "# VS (versus): Target denomination currency (e.g., USD, GBP, EUR)\n",
    "VS = \"USD\" \n",
    "START_DATE = \"2018-01-01\"\n",
    "END_DATE = \"2026-01-01\" # Updated for current research cycle\n",
    "INTERVAL = \"1d\"        # Daily resolution\n",
    "PRICE_FIELD = \"Close\"\n",
    "\n",
    "# Build tickers according to Yahoo Finance nomenclature (e.g., ETH-USD)\n",
    "tickers = [f\"{c}-{VS}\" for c in cryptos]\n",
    "\n",
    "# Download Raw Data via yfinance API\n",
    "raw_data = yf.download(\n",
    "                        tickers=tickers,\n",
    "                        start=START_DATE,\n",
    "                        end=END_DATE,\n",
    "                        interval=INTERVAL,\n",
    "                        group_by=\"ticker\",\n",
    "                        auto_adjust=False,\n",
    "                        progress=False,\n",
    "                        threads=True\n",
    "                )\n",
    "\n",
    "# Transformation: Consolidate data into a multi-column DataFrame\n",
    "crypto_prices = pd.DataFrame({c: raw_data[(f\"{c}-{VS}\", PRICE_FIELD)] for c in cryptos})\n",
    "crypto_prices.index.name = \"Date\"\n",
    "\n",
    "# Data Cleaning: Remove rows with null values to ensure model veracity\n",
    "crypto_prices = crypto_prices.dropna(how=\"any\")\n",
    "\n",
    "# Local Persistence: Create directories if they do not exist\n",
    "DATA_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "crypto_prices.to_csv(DATA_PATH)\n",
    "\n",
    "print(f\"Data successfully saved to: {DATA_PATH}\")\n",
    "print(\"\\n--- Initial Data Preview ---\")\n",
    "print(crypto_prices.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b74cf1c",
   "metadata": {},
   "source": [
    "### Visualisation: Raw vs. Normalised Data Analysis\n",
    "\n",
    "We can initiate our analysis by examining the historical price trends of the selected assets. Visualising the data is a critical step in identifying volatility patterns and potential correlations before training the model. \n",
    "\n",
    "The visualisations below provide two distinct perspectives: the first plot illustrates raw market prices, while the second employs normalised data to facilitate a direct relative performance comparison.\n",
    "\n",
    "#### A. Raw Price Graphs (The \"Scale\" Problem)\n",
    "The first plot illustrates the actual market prices for BTC and ETH.\n",
    "* **Limitation**: Because BTC and ETH possess vastly different market values (e.g., $60,000 vs $2,500), their price lines appear significantly separated on the Y-axis.\n",
    "* **Visual Challenge**: This disparity in scale makes it difficult to determine if the assets are moving in synchrony or to identify which asset is outperforming the other in percentage terms.\n",
    "\n",
    "#### B. Normalised Data Graphs (The Advantage)\n",
    "`norm = (crypto_prices / crypto_prices.iloc[0]) * 100`\n",
    "Normalisation scales both assets so they originate from the same base point (100) on the initial day of the dataset.\n",
    "\n",
    "**Advantages of Normalised Analysis:**\n",
    "1. **Direct Comparison**: With both assets indexed at 100, you can immediately identify which asset has achieved a higher cumulative percentage return over the period.\n",
    "2. **Visual Correlation**: It is significantly easier to identify \"decoupling\" events—periods where the assets' price trends diverge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64d3a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two plots next to each other\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Raw prices (often hard to compare due to different scales)\n",
    "ax1.plot(crypto_prices.index, crypto_prices[\"ETH\"], label=\"ETH (raw)\")\n",
    "ax1.plot(crypto_prices.index, crypto_prices[\"BTC\"], label=\"BTC (raw)\")\n",
    "ax1.set_title(\"Raw prices (different scales)\")\n",
    "ax1.set_xlabel(\"Date\")\n",
    "ax1.set_ylabel(f\"Price (your quote currency)\")\n",
    "ax1.legend()\n",
    "\n",
    "# Normalised prices (starts both at 100)\n",
    "# Normalise the prices for better relative performance analysis\n",
    "norm = (crypto_prices / crypto_prices.iloc[0]) * 100 \n",
    "ax2.plot(norm.index, norm[\"ETH\"], label=\"ETH (normalised)\")\n",
    "ax2.plot(norm.index, norm[\"BTC\"], label=\"BTC (normalised)\")\n",
    "ax2.set_title(\"Normalised (100 at start)\")\n",
    "ax2.set_xlabel(\"Date\")\n",
    "ax2.set_ylabel(\"Normalised value\")\n",
    "ax2.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722b2555",
   "metadata": {},
   "source": [
    "### Statistical Correlation and Log-Return Transformation\n",
    "\n",
    "Before proceeding to model training, we must quantify the statistical relationship between our chosen assets. This step ensures that the independent variable (BTC) is a statistically significant predictor for the dependent variable (ETH), thereby justifying the selection of an AI model for our price prediction engine.\n",
    "\n",
    "#### 1. Why Pearson Correlation?\n",
    "The script below calculates the **Pearson Correlation Coefficient** for both raw prices and log-returns.\n",
    "* **Definition**: This metric measures the linear correlation between two variables, ranging from -1 to +1.\n",
    "* **Utility**: A high positive correlation (closer to +1.0) suggests that when BTC moves, ETH is likely to move in the same direction. A high negative correlation (closer to -1.0) suggests that when BTC moves, ETH is likely to move in the opposite direction.\n",
    "* **Interpretation**: If the correlation result is weak (within the range of $[-0.4, 0.4]$), we can assume these assets lack a significant linear relationship, necessitating further analysis. Conversely, a strong correlation justifies the use of a **Linear Regression** model.\n",
    "\n",
    "#### 2. Why Log-Returns?\n",
    "`log_returns = np.log(crypto_prices).diff().dropna()`\n",
    "Raw price data is often **non-stationary**, meaning its statistical properties (such as mean and variance) change over time, which can lead to spurious correlations.\n",
    "* **Stationarity**: Log-returns focus on the **proportional change** rather than absolute values, helping to stabilise the data for more reliable training.\n",
    "* **Relative Measurement**: This transformation allows us to measure growth rates consistently, regardless of the price magnitude (e.g., comparing a $100,000 asset to a $2,000 asset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889fd46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Analysis\n",
    "corr = crypto_prices[\"ETH\"].corr(crypto_prices[\"BTC\"])\n",
    "\n",
    "# Log returns analysis\n",
    "log_returns = np.log(crypto_prices).diff().dropna() \n",
    "corr_returns = log_returns[\"ETH\"].corr(log_returns[\"BTC\"])\n",
    "\n",
    "print(f\"Pearson correlation (prices):      {corr:.4f}\")\n",
    "print(f\"Pearson correlation (log returns): {corr_returns:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94314dd",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "Based on the correlation results, which indicate a strong positive relationship, we can justify the use of a **Linear Regression** model.\n",
    "\n",
    "#### 1. Feature Engineering: Percentage Change\n",
    "Following the initial analysis, many data science projects transition into **Feature Engineering**. This phase aims to enhance model accuracy through the incorporation of additional data, the generation of composite features, or data transformations.\n",
    "\n",
    "`ret = crypto_prices.pct_change().dropna()`\n",
    "Following the observation of the **normalised price data graph**, we convert raw prices into **percentage changes** (returns). This transformation is essential to prevent **spurious regression** caused by the non-stationarity inherent in raw price data. Utilising returns ensures the model identifies the **relative relationship** between asset movements rather than absolute price levels.\n",
    "\n",
    "\n",
    "\n",
    "#### 2. Defining Variables ($X$ and $y$)\n",
    "In our model, we define:\n",
    "* **Independent Variable ($X$)**: The returns of **Bitcoin (BTC)**. This acts as the \"predictor\" or input signal.\n",
    "* **Dependent Variable ($y$)**: The returns of **Ethereum (ETH)**. This is the \"target\" variable we aim to forecast.\n",
    "\n",
    "#### 3. Model Fitting\n",
    "`model = LinearRegression().fit(X, y)`\n",
    "The algorithm calculates the \"line of best fit\" by minimising the sum of the squares of the vertical deviations (residuals) between each data point and the line. For a deep dive into the implementation, refer to the [scikit-learn Linear Regression documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html).\n",
    "\n",
    "\n",
    "#### 4. Performance Metrics (Evaluation)\n",
    "To evaluate whether the model is reliable for on-chain deployment, we calculate two primary metrics:\n",
    "* **R-Squared ($R^2$)**: Represents the proportion of variance for ETH explained by BTC. An $R^2$ value approaching 1.0 indicates a strong predictive relationship.\n",
    "* **Mean Absolute Error (MAE)**: Measures the average magnitude of prediction errors. This is vital for assessing the \"risk\" or accuracy of our decentralised price engine.\n",
    "\n",
    "#### 5. Extracting Coefficients ($\\alpha$ and $\\beta$)\n",
    "The most critical output for our smart contract development is the extraction of the model parameters:\n",
    "* **Slope ($a$)**: Represents the expected change in ETH for every 1% change in BTC.\n",
    "* **Intercept ($b$)**: The predicted return of ETH when the BTC return is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5472b1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model generation\n",
    "ret = crypto_prices.pct_change().dropna()\n",
    "X = ret[[\"BTC\"]].values\n",
    "y = ret[\"ETH\"].values\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "r2 = r2_score(y, y_pred)\n",
    "mae = mean_absolute_error(y, y_pred)\n",
    "\n",
    "a = float(model.coef_[0])\n",
    "b = float(model.intercept_)\n",
    "\n",
    "# MODEL ACCURACY\n",
    "print(\"Linear Regression (log returns): ETH_ret = a * BTC_ret + b\")\n",
    "print(f\"a (slope): {a:.8f}\")\n",
    "print(f\"b (intercept): {b:.8f}\")\n",
    "print(f\"R²: {r2:.4f} | MAE: {mae:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c2cae3",
   "metadata": {},
   "source": [
    "### Interpreting the Model Results\n",
    "\n",
    "- **R² (0.6623)** — **\"Good/Strong\"**: In financial time-series analysis, an R-squared above 0.60 is considered strong. It indicates that BTC’s movement captures the majority of ETH’s price action, justifying the use of a simple linear model rather than a more complex non-linear one.\n",
    "\n",
    "- **MAE (0.0174)** — **\"High Precision\"**: An average error of 1.7% is relatively low for volatile crypto assets. This suggests the model is stable enough to be used for a decentralised price engine without causing extreme mispricing.\n",
    "\n",
    "- **Slope (1.0674)** — **\"Reliable Correlation\"**: A slope near 1.0 confirms a near-identical beta relationship. If the slope were too high (e.g., >5.0) or too low, it would indicate an unstable relationship that would be risky to hardcode into a smart contract.\n",
    "\n",
    "**Conclusion**: The evaluation metrics indicate that the trained model is statistically significant and possesses sufficient predictive accuracy for financial forecasting. Consequently, this model is suitable for our implementation.\n",
    "\n",
    "The following code block facilitates manual prediction. You may use it to test various BTC and ETH price scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a81fbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price prediction manual test\n",
    "# Change values to try for yourself\n",
    "btc_prev = 132_000\n",
    "btc_now  = 70_000\n",
    "btc_ret = np.log(btc_now / btc_prev)\n",
    "\n",
    "eth_prev = 3_200  # last ETH price\n",
    "eth_ret_pred = model.predict([[btc_ret]])[0]   # your returns model\n",
    "eth_now_pred = eth_prev * np.exp(eth_ret_pred)\n",
    "\n",
    "print(\"Predicted ETH price:\", eth_now_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c268ac7f",
   "metadata": {},
   "source": [
    "### Model Export\n",
    "\n",
    "#### 1. The Model Dictionary\n",
    "\n",
    "We construct a `model_dict` to store both raw statistical values and metadata required for the next phase:\n",
    "\n",
    "- **Metadata:** `fit_on`, `x`, and `y` define the training scope, while `start_date` and `end_date` provide a temporal audit trail for research reproducibility.\n",
    "- **Coefficients:** `slope_a` and `intercept_b` are stored as floats for high-precision off-chain verification.\n",
    "- **Evaluation Metrics:** `r2` and `mae` are included to allow the smart contract consumer to verify the model’s veracity before execution.\n",
    "\n",
    "### 2. EVM Compatibility: Fixed-Point Scaling\n",
    "\n",
    "The most critical part of this code is the creation of `slope_a_scaled_int` and `intercept_b_scaled_int`.\n",
    "\n",
    "- **The Constraint:** The Ethereum Virtual Machine (EVM) does not natively support floating-point decimals.\n",
    "- **The Solution:** We apply a scaling factor (e.g., *SCALE* = 10^18) to convert the coefficients into large integers:\n",
    "\n",
    "  `scaled_int = round(float_value × SCALE)`\n",
    "\n",
    "- **String Storage:** We store these as strings to prevent precision loss or overflow issues when the data is parsed by JavaScript-based tooling like **Ethers.js** or **Web3.js**.\n",
    "\n",
    "### 3. JSON File\n",
    "\n",
    "The model is written to `model.json` file, which serves as the payload for decentralised storage Pinata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38be7cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALE = 10**18\n",
    "# Save model parameters\n",
    "model_dict = {\n",
    "    \"fit_on\": \"log_returns\",\n",
    "    \"x\": \"BTC\",\n",
    "    \"y\": \"ETH\",\n",
    "    \"slope_a\": float(a),\n",
    "    \"intercept_b\": float(b),\n",
    "    \"scale\": str(SCALE),  # store big ints as strings for safe parsing in JS tooling\n",
    "    \"slope_a_scaled_int\": str(int(round(a * SCALE))),\n",
    "    \"intercept_b_scaled_int\": str(int(round(b * SCALE))),\n",
    "    \"r2\": float(r2),\n",
    "    \"mae\": float(mae),\n",
    "    \"start_date\": str(log_returns.index.min().date()),\n",
    "    \"end_date\": str(log_returns.index.max().date()),\n",
    "}\n",
    "\n",
    "MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(MODEL_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(model_dict, f, indent=2)\n",
    "\n",
    "print(\"Saved model parameters to:\", MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1be720a",
   "metadata": {},
   "source": [
    "### PINATA\n",
    "\n",
    "Now that we have exported our model, we can upload the `model.json` file to **Pinata (IPFS)**.\n",
    "\n",
    "First, we must create a Pinata account and generate a `PINATA_JWT`. Detailed guidance for this can be found here: **[Pinata API Key Documentation](https://knowledge.pinata.cloud/en/articles/6191471-how-to-create-an-pinata-api-key)**. After generating your JWT, paste it into the code below. The script will then read and upload the model file. It also provides the **CID (Content Identifier)** and the gateway path for the Remix smart contract to reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aeb5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPLOADING MODEL TO PINATA IPFS\n",
    "PINATA_JWT = \"\" # Paste your Pinata_JWS here.\n",
    "\n",
    "url = \"https://api.pinata.cloud/pinning/pinFileToIPFS\"\n",
    "headers = {\"Authorization\": f\"Bearer {PINATA_JWT.strip()}\"}\n",
    "\n",
    "# Upload the model file (MODEL_PATH should point to your JSON file)\n",
    "with MODEL_PATH.open(\"rb\") as f:\n",
    "    files = {\"file\": (MODEL_PATH.name, f, \"application/json\")}\n",
    "    resp = requests.post(url, headers=headers, files=files, timeout=120)\n",
    "\n",
    "resp.raise_for_status()\n",
    "out = resp.json()\n",
    "cid = out[\"IpfsHash\"]\n",
    "\n",
    "print(\"Stored on Pinata CID:\", cid)\n",
    "print(\"Gateway URL:\", f\"https://gateway.pinata.cloud/ipfs/{cid}\")\n",
    "\n",
    "print(\"Successfully saved CID to:\", cid_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7028d181",
   "metadata": {},
   "source": [
    "Finally, we record the IPFS deployment metadata in a local manifest file. This ipfs_manifest.json provides a permanent record of the **CID**, **timestamp**, and **gateway URLs** required for subsequent smart contract integration and research auditing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a410836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STORING MODEL PARAMETERS LOCALLY FOR ETHEREUM USE\n",
    "manifest = {\n",
    "    \"cid\": cid,\n",
    "    \"pinned_via\": \"pinata\",\n",
    "    \"artifact\": str(MODEL_PATH.name),\n",
    "    \"pinned_at_utc\": datetime.now(timezone.utc).isoformat(),\n",
    "    \"pinata_response\": out,\n",
    "    \"gateway_urls\": [\n",
    "        f\"https://gateway.pinata.cloud/ipfs/{cid}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "MANIFEST_PATH = Path(\"./model/ipfs_manifest.json\")\n",
    "\n",
    "with MANIFEST_PATH.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(manifest, f, indent=2)\n",
    "\n",
    "print(\"Saved manifest to:\", MANIFEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00551d2",
   "metadata": {},
   "source": [
    "## Remix IDE and Chainlink\n",
    "\n",
    "### Technical Overview: Chainlink and IPFS Integration\n",
    "\n",
    "In a decentralised architecture, smart contracts are inherently isolated and cannot natively perform HTTP requests to external storage systems such as the **InterPlanetary File System (IPFS)**. This limitation is commonly referred to as the **Oracle Problem**. To bridge this gap, we use **Chainlink**, a **Decentralised Oracle Network (DON)**, as a secure middleware layer that connects on-chain contracts to off-chain data sources.\n",
    "\n",
    "#### The Role of a Decentralised Oracle Network (DON)\n",
    "\n",
    "A DON consists of multiple independent oracle nodes that retrieve data from off-chain environments, optionally aggregate results to improve integrity, and then deliver a verified response back to the on-chain contract.\n",
    "\n",
    "In this project, Chainlink oracle nodes fetch the `model.json` file from **Pinata**, parse the required fields, and return the extracted values to the **Solidity** contract."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5289a0",
   "metadata": {},
   "source": [
    "### CHAINLINK\n",
    "\n",
    "For further information about Chainlink, please refer to the official documentation:\n",
    "- **Chainlink Documentation:** [Chainlink Documentation](https://docs.chain.link/chainlink-functions/getting-started)\n",
    "\n",
    "To run this lab, you will need testnet funds (for example, on **Ethereum Sepolia**) so you can deploy contracts and pay gas for oracle-related interactions.\n",
    "\n",
    "1. **Set up a wallet (e.g., MetaMask)** and switch to the required test network.\n",
    "2. **Get testnet tokens** ( **Sepolia ETH** and **testnet LINK**) using the Chainlink faucets: [Faucets](https://faucets.chain.link)  \n",
    "\n",
    "Once your wallet is funded, you can proceed with deploying and testing the Remix + Chainlink components in the next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4b3780",
   "metadata": {},
   "source": [
    "Copy and paste the code below into a new file on the Remix IDE. Then, compile and deploy the contract."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a39dd5e",
   "metadata": {},
   "source": [
    "```solidity\n",
    "// SPDX-License-Identifier: MIT\n",
    "pragma solidity ^0.8.19;\n",
    "\n",
    "// UPDATE MODEL PARAMETERS\n",
    "// ARGS = [\"Qme3DCaQatkF3SYrX9BvDHAzNzH78wkU9415K222u467R3\"] (CID)\n",
    "// CID: Chainlink subscription ID\n",
    "// SOURCE: JS CODE - It is hardcoded into this smart contract.\n",
    "\n",
    "import {FunctionsClient} from \"@chainlink/contracts/src/v0.8/functions/v1_0_0/FunctionsClient.sol\";\n",
    "import {FunctionsRequest} from \"@chainlink/contracts/src/v0.8/functions/v1_0_0/libraries/FunctionsRequest.sol\";\n",
    "import {ConfirmedOwner} from \"@chainlink/contracts/src/v0.8/shared/access/ConfirmedOwner.sol\";\n",
    "\n",
    "contract MLPredictor is FunctionsClient, ConfirmedOwner {\n",
    "    using FunctionsRequest for FunctionsRequest.Request;\n",
    "\n",
    "    // Hardcoded model parameters stored on-chain\n",
    "    int256 public slope_a;\n",
    "    int256 public intercept_b;\n",
    "    int256 public constant SCALE = 1e18;\n",
    "\n",
    "    // Sepolia Router & DON Configuration\n",
    "    // If fails, check the most recent values for the router and the donId\n",
    "    address router = 0xb83E47C2bC239B3bf370bc41e1459A34b41238D0;\n",
    "    bytes32 donId = 0x66756e2d657468657265756d2d7365706f6c69612d3100000000000000000000;\n",
    "    uint32 gasLimit = 300000;\n",
    "\n",
    "    // JS Code logic for Chainlink DON to optimise the on-chain operations and reduce gas use\n",
    "    string public constant SOURCE = \n",
    "        \"const cid = 'Qme3DCaQatkF3SYrX9BvDHAzNzH78wkU9415K222u467R3'; \"\n",
    "        \"const url = 'https://gateway.pinata.cloud/ipfs/' + cid; \"\n",
    "        \"const response = await Functions.makeHttpRequest({ url: url }); \"\n",
    "        \"if (response.error) throw Error('IPFS Fetch Failed'); \"\n",
    "        \"const data = response.data; \"\n",
    "        \"const slope = BigInt(data.slope_a_scaled_int); \"\n",
    "        \"const intercept = BigInt(data.intercept_b_scaled_int); \"\n",
    "        \"return Functions.encodeUint256Array([slope, intercept]);\";\n",
    "\n",
    "    event ModelUpdated(int256 slope, int256 intercept);\n",
    "\n",
    "    constructor() FunctionsClient(router) ConfirmedOwner(msg.sender) {}\n",
    "\n",
    "    /**\n",
    "     * @notice Fetch parameters using your Chainlink Subscription ID\n",
    "     * @param subId Your Chainlink Subscription ID\n",
    "     */\n",
    "    function updateModel(uint64 subId) external onlyOwner {\n",
    "        FunctionsRequest.Request memory req;\n",
    "        req.initializeRequestForInlineJavaScript(SOURCE); // Uses hardcoded SOURCE\n",
    "\n",
    "        _sendRequest(req.encodeCBOR(), subId, gasLimit, donId);\n",
    "    }\n",
    "\n",
    "    function fulfillRequest(bytes32 /*requestId*/, bytes memory response, bytes memory /*err*/) internal override {\n",
    "        (int256 _slope, int256 _intercept) = abi.decode(response, (int256, int256));\n",
    "        slope_a = _slope;\n",
    "        intercept_b = _intercept;\n",
    "        emit ModelUpdated(_slope, _intercept);\n",
    "    }\n",
    "\n",
    "    function predictEth(uint256 oldBtc, uint256 newBtc, uint256 oldEth) public view returns (uint256) {\n",
    "        require(slope_a != 0, \"Model not yet updated\");\n",
    "        int256 btcReturn = (int256(newBtc) - int256(oldBtc)) * SCALE / int256(oldBtc);\n",
    "        int256 ethReturn = (slope_a * btcReturn / SCALE) + intercept_b;\n",
    "        return uint256(int256(oldEth) + (int256(oldEth) * ethReturn / SCALE));\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da992a48",
   "metadata": {},
   "source": [
    "### Interacting with the Deployed Contract in Remix\n",
    "\n",
    "After deploying the contract, scroll down to **Deployed Contracts**.\n",
    "\n",
    "#### Step 1: Update the on-chain model parameters (slope and intercept)\n",
    "\n",
    "1. Locate the function **`updateModel`**.\n",
    "2. Enter your **`subId`** (your Chainlink Functions subscription ID).\n",
    "3. Click **Transact**.\n",
    "\n",
    "> **Expected result:** The request is sent to the Chainlink DON. Once it is fulfilled, the contract should store the latest **slope** and **intercept** values on-chain. You can verify the updated values by clicking the corresponding getter functions.\n",
    "\n",
    "> **Note:** `updateModel` is a transaction, so it requires some tokens. If you do not have any tokens, please obtain testnet tokens from the faucet given above.\n",
    "\n",
    "#### Step 2: Run a prediction using the stored model\n",
    "\n",
    "1. Locate the function **`predictETH`**.\n",
    "2. Enter the required inputs:\n",
    "   - `oldBTC`\n",
    "   - `newBTC`\n",
    "   - `oldETH`\n",
    "3. Click **Call** (not Transact).\n",
    "\n",
    "> **Expected result:** The function returns a predicted value for **`newETH`**, computed using the on-chain model parameters (slope/intercept) and your supplied inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6713e96f",
   "metadata": {},
   "source": [
    "### Chainlink Functions Script: Fetching and Parsing `model.json` from IPFS\n",
    "\n",
    "The JavaScript code below is embedded into the smart contract. When the contract sends a request, this script is transmitted to the **Chainlink Decentralised Oracle Network (DON)** for off-chain execution.\n",
    "\n",
    "When Chainlink DON receives it, they execute the script to:\n",
    "\n",
    "1. **Fetch `model.json` from IPFS (via the Pinata gateway)** using the provided CID.\n",
    "2. **Parse the JSON payload** and extract the model parameters.\n",
    "3. **ABI-encode the extracted values** into a byte array format that Solidity can safely decode.\n",
    "4. **Return the encoded result on-chain**, where the smart contract decodes and stores the model parameters.\n",
    "\n",
    "This workflow allows the contract to access off-chain data without directly performing HTTP requests, while still keeping the final parameters verifiable and usable within Solidity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b0d9c8",
   "metadata": {},
   "source": [
    "```Javascript\n",
    "\n",
    "// Step 1: Fetch the model JSON from IPFS via Pinata gateway\n",
    "const cid = \"Qme3DCaQatkF3SYrX9BvDHAzNzH78wkU9415K222u467R3\";\n",
    "const url = `https://gateway.pinata.cloud/ipfs/${cid}`;\n",
    "\n",
    "const res = await Functions.makeHttpRequest({ url });\n",
    "\n",
    "// Handle transport / request errors\n",
    "if (res.error) {\n",
    "  throw Error(`IPFS fetch failed: ${JSON.stringify(res.error)}`);\n",
    "}\n",
    "\n",
    "// Step 2: Parse and validate the JSON payload\n",
    "const data = res.data;\n",
    "if (!data) throw Error(\"IPFS fetch succeeded but returned empty data.\");\n",
    "\n",
    "// Validate required fields exist\n",
    "if (data.slope_a_scaled_int === undefined || data.intercept_b_scaled_int === undefined) {\n",
    "  throw Error(\"Missing required fields: slope_a_scaled_int and/or intercept_b_scaled_int.\");\n",
    "}\n",
    "\n",
    "// Step 3: Extract values (as uint256-compatible BigInt)\n",
    "const slope = BigInt(data.slope_a_scaled_int);\n",
    "const intercept = BigInt(data.intercept_b_scaled_int);\n",
    "\n",
    "// Step 4: Return ABI-encoded bytes back to Solidity\n",
    "// Solidity side will decode this as uint256[]\n",
    "return Functions.encodeUint256Array([slope, intercept]);\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UoBTA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
